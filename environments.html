<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Environments | EARL: Environments for Autonomous Learning</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
  <link rel="stylesheet" href="vendor/simple-line-icons/css/simple-line-icons.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/monokai.min.css">

  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;500;600;700&display=swap" rel="stylesheet"> 
<link href="https://fonts.googleapis.com/css2?family=Zilla+Slab:wght@300;400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet">

  <!-- Plugin CSS -->
  <link rel="stylesheet" href="device-mockups/device-mockups.min.css">

  <!-- Custom styles for this template -->
  <link href="css/new-age.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>

</head>

<body id="page-top">

<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="index.html">EARL</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="overview.html">Overview</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="environments.html" style="color:rgba(0,0,0,0.3) !important">Environments</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://arxiv.org/abs/TBD">Paper</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="https://github.com/architsharma97/persistent_rl_benchmark"">Code</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  
<section class="features" id="alltasks">
    <div class="container">
        <!--<h2>Meta-World Evaluation Modes</h2>-->
      <h2>Environments</h2>
      <h3>Motivation</h3>
      <p>
        <strong>Representative Autonomous Settings.</strong> We include a broad array of tasks that reflect the types of autonomous learning scenarios agents may encounter in the real world. This includes different problems in manipulation and locomotion, and tasks with multiple object interactions for which it would be challenging to instrument resets. We also ensure that both the continuing and deployment evaluation protocols of ARL are realistic representative evaluations. 
      </p>
      <p>
        <strong>Directed Exploration.</strong> In the autonomous setting, it may be necessary to practice a task multiple times from different initial states. This gives rise to the need for agents to learn rich reset behaviors. For example, in the instance of a robot learning to interact with multiple objects in a kitchen, the robot must learn to implicitly or explicitly compose different reset behaviors.</p>
      </p>
      <h3>Tabletop-Organization</h3>
      <div class="row">
        <div class="col-sm">
          <p>
            The Tabletop-Organization environment consists of a gripper agent, modeled as a pointmass, which can grasp objects that are close to it. The agent's goal is to bring a mug to four different locations designated by a goal coaster. The agent's reward function is a sparse indicator function when the mug is placed at the goal location.
        </p>
        </div>
        <div class="col-sm">
          <div class="text-center" >
        <video autoplay loop muted playsinline style="width: 100%" class="rounded">
          <source src="figures/tabletop.mp4" type="video/mp4">
        </video>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <!--<h2>Meta-World Evaluation Modes</h2>-->
     <h3>Sawyer-Door</h3>
    <div class="row">
      <div class="col-sm">
        <p>
          The Sawyer-Door task, from the <a href="https://meta-world.github.io">MetaWorld benchmark</a>, consists of a Sawyer robot arm who's goal is to close the door whenever it is in an open position. The task reward is a sparse indicator function based on the angle of the door. Repeatedly practicing this task implicitly requires the agent to learn to open the door.
        </p>
      </div>
      <div class="col-sm">
        <video autoplay loop muted playsinline style="width: 100%" class="rounded">
          <source src="figures/door_video.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>

    <div class="container">
      <h3>Sawyer-Peg</h3>
      <div class="row">
        <div class="col-sm">
          <p>
            The Sawyer-Peg task, also from <a href="https://meta-world.github.io">MetaWorld</a>, consists of a Sawyer robot tasked with inserting a peg into the designated goal location. The task reward is a sparse indicator function for when the peg is inserted into the goal location.
          </p>
        </div>
        <div class="col-sm">
          <video autoplay loop muted playsinline style="width: 100%" class="rounded">
            <source src="figures/peg_video.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    
    <div class="container">
      <h3>Franka-Kitchen</h3>
      <div class="row">
        <div class="col-sm">
          <p>
              The Franka-Kitchen (<a href="https://arxiv.org/abs/1910.11956">Gupta et al., 2019</a>) is a domain where a 9-DoF robot, situated in a kitchen environment, is required to solve tasks consisting of compound object interactions. The environment consists of a microwave, a hinged cabinet, a burner, and a slide cabinet. One example task is to open the microwave, door and burner. 
          </p>
          <p>
            This domain presents a number of distinct challenges for ARL. First, the compound nature of each task results in a challenging long horizon problem, which introduces exploration and credit assignment challenges. Second, while generalization is important in solving the environment, combining reset behaviors are equally important given the compositional nature of the task.
          </p>
        </div>
        <div class="col-sm">
          <div class="text-center">
            <video autoplay loop muted playsinline style="width: 100%" class="rounded">
              <source src="figures/kitchen_video.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

    </div>


    <div class="container">
        <h3>DHand-LightBulb</h3>
        <div class="row">
          <div class="col-sm">
            <p>
              The DHand-Lightbulb environment (<a href="https://arxiv.org/abs/2104.11203">Gupta et al., 2021</a>) consists of a 22-DoF 4 fingered hand, mounted on a 6 DoF Sawyer robot. The task in this domain is for the robot to pickup a lightbulb to a specific location. The high-dimensional action space makes the task extremely challenging.
          </p>
          </div>
          <div class="col-sm">
            <div class="text-center">
              <video autoplay loop muted playsinline style="width: 100%" class="rounded">
                <source src="figures/bulb_video.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
    </div>

    <div class="container">
        <h3>Minitaur-Pen</h3>
        <div class="row">
          <div class="col-sm">
            <p>
              The Minitaur-Pen task (<a href="https://pybullet.org">Coumans and Bai, 2016</a>) consists of an 8-DoF Minitaur robot confined to a pen environment. The goal of the agent is to navigate to a set of goal locations in the pen. The task is designed to mimic the setup of leaving a robot to learn to navigate within an enclosed setting in an autonomous fashion.
          </p>
          </div>
          <div class="col-sm">
            <div class="text-center">
              <video autoplay loop muted playsinline style="width: 100%" class="rounded">
                <source src="figures/minitaur_video.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
    </div>
</section>


  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/new-age.min.js"></script>

</body>

</html>
